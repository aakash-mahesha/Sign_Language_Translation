{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4863b3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3f676a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadDataForAlphabet(alphabet):\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_hands = mp.solutions.hands\n",
    "    cap = cv2.VideoCapture(0,cv2.CAP_DSHOW)\n",
    "    rows=[]\n",
    "    with mp_hands.Hands(\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5,\n",
    "        max_num_hands=1) as hands:\n",
    "        frames=1;\n",
    "        while True:\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "              # If loading a video, use 'break' instead of 'continue'.\n",
    "                continue\n",
    "            image=cv2.flip(image,1)\n",
    "            if frames<=150:\n",
    "                cv2.putText(image, \"get ready to read \"+element, (80, 400), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n",
    "                \n",
    "            # Flip the image horizontally for a later selfie-view display, and convert\n",
    "            # the BGR image to RGB.\n",
    "            else:\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                # To improve performance, optionally mark the image as not writeable to\n",
    "                # pass by reference.\n",
    "\n",
    "                image.flags.writeable = False\n",
    "                results = hands.process(image)\n",
    "\n",
    "                # Draw the hand annotations on the image.\n",
    "                image.flags.writeable = True\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                cv2.putText(image,\"adjust hand gesture for \"+element, (80,400), cv2.FONT_HERSHEY_SIMPLEX,0.9,(0,0,255),2)\n",
    "                if results.multi_hand_landmarks:\n",
    "                    row=[alphabet]\n",
    "                    for hand_landmarks in results.multi_hand_landmarks:\n",
    "\n",
    "                        for hand_landmark in hand_landmarks.landmark:\n",
    "                            row.append(hand_landmark.x)\n",
    "                            row.append(hand_landmark.y)\n",
    "#                             print('x:',hand_landmark.x)\n",
    "#                             print('y:',hand_landmark.y)\n",
    "\n",
    "                        mp_drawing.draw_landmarks(\n",
    "                        image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                    rows.append(row)\n",
    "            cv2.imshow('MediaPipe Hands', image)\n",
    "            frames+=1\n",
    "            if frames>450:\n",
    "                break\n",
    "\n",
    "            if cv2.waitKey(5) & 0xFF == 27:\n",
    "                break\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    \n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c57bf114",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_labels=['value']\n",
    "for i in range(0,21):\n",
    "    column_labels.append('x'+str(i))\n",
    "    column_labels.append('y'+str(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d54fc602",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the alphabet or character: A\n",
      "Enter an another word or Character: n\n",
      "Dataset has been created at the path E:\\Major Project\\Datasets!!!\n",
      "Happy coding\n"
     ]
    }
   ],
   "source": [
    "labels=[]\n",
    "df_lists=[]\n",
    "while True:\n",
    "    element=input('Enter the alphabet or character: ')\n",
    "    rows=ReadDataForAlphabet(element)\n",
    "    df_lists.append(pd.DataFrame(rows,columns=column_labels))\n",
    "    repeat=True\n",
    "    while True:\n",
    "        choice=input('Enter an another word or Character: ')\n",
    "        if choice=='y':\n",
    "            break\n",
    "        elif choice=='n':\n",
    "            repeat=False\n",
    "            break\n",
    "        else:\n",
    "            print('Enter y or n')\n",
    "    if repeat==False:\n",
    "        break\n",
    "data=pd.concat(df_lists,ignore_index=True)\n",
    "path=os.path.join(os.getcwd(),'Datasets')\n",
    "if os.path.exists(path):\n",
    "    shutil.rmtree(path)\n",
    "os.makedirs(path)\n",
    "data.to_csv(os.path.join(path,'custom_dataset.csv'),index=False)\n",
    "print('Dataset has been created at the path '+path+'!!!\\nHappy coding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0b277e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
