{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68257e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cc0c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_surrounding=None\n",
    "accumulated_weight=0.5\n",
    "\n",
    "ROI_top=100\n",
    "ROI_bottom=300\n",
    "ROI_right=150\n",
    "ROI_left=350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc893cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAccumlatedAvg(frame,accumulated_weight):\n",
    "    global background_surrounding\n",
    "    if background_surrounding is None:\n",
    "        background_surrounding=frame.copy().astype(\"float\")\n",
    "        return None\n",
    "    cv2.accumulateWeighted(frame,background_surrounding,accumulated_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed7a3c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def segmentingHand(frame,threshold=25):\n",
    "#     global background_surrounding\n",
    "    \n",
    "#     difference=cv2.absdiff(background_surrounding.astype(\"uint8\"),frame)\n",
    "#     _,thresholded=cv2.threshold(difference,threshold,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "#     contours,hierarchy=cv2.findContours(thresholded.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "#     if len(contours)==0:\n",
    "#         return None\n",
    "#     else:\n",
    "#         max_hand_segment_count=max(contours,key=cv2.contourArea)\n",
    "#         return (thresholded,max_hand_segment_count)\n",
    "\n",
    "def segmentingHand(frame,threshold=25):\n",
    "    global background_surrounding\n",
    "    \n",
    "    difference=cv2.absdiff(background_surrounding.astype(\"uint8\"),frame)\n",
    "    _,thresholded=cv2.threshold(difference,threshold,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "#     contours,hierarchy=cv2.findContours(thresholded.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    \n",
    "#     if len(contours)==0:\n",
    "#         return None\n",
    "#     else:\n",
    "#         max_hand_segment_count=max(contours,key=cv2.contourArea)\n",
    "#         return (thresholded,max_hand_segment_count)\n",
    "    edges=cv2.canny(thresholded.copy(),100,200)\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63f5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "signs=['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "path=os.getcwd()\n",
    "for element in signs:\n",
    "    \n",
    "    train_path=os.path.join(path,os.path.join('Data',os.path.join('train',element)))\n",
    "    test_path=os.path.join(path,os.path.join('Data'),os.path.join('test',element))\n",
    "    os.makedirs(train_path)\n",
    "    os.makedirs(test_path)\n",
    "    \n",
    "    cam = cv2.VideoCapture(0,cv2.CAP_DSHOW)         #cam=cv2.VideoCapture(0) for non windows systems\n",
    "\n",
    "    num_frames = 0\n",
    "    # element = 1\n",
    "    num_imgs_taken = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cam.read()\n",
    "\n",
    "        # filpping the frame to prevent inverted image of captured frame...\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        frame_copy = frame.copy()\n",
    "\n",
    "        roi = frame[ROI_top:ROI_bottom, ROI_right:ROI_left]\n",
    "\n",
    "        gray_frame = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        gray_frame = cv2.GaussianBlur(gray_frame, (9, 9), 0)\n",
    "\n",
    "        if num_frames < 60:\n",
    "            calculateAccumlatedAvg(gray_frame, accumulated_weight)\n",
    "            if num_frames <= 59:\n",
    "\n",
    "                cv2.putText(frame_copy, \"FETCHING BACKGROUND...PLEASE WAIT\", (80, 400), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n",
    "                #cv2.imshow(\"Sign Detection\",frame_copy)\n",
    "\n",
    "        #Time to configure the hand specifically into the ROI...\n",
    "        elif num_frames <= 300: \n",
    "\n",
    "            hand = segmentingHand(gray_frame)\n",
    "\n",
    "            cv2.putText(frame_copy, \"Adjust hand...Gesture for\" + str(element), (200, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "            # Checking if hand is actually detected by counting number of contours detected...\n",
    "            if hand is not None:\n",
    "\n",
    "                thresholded, hand_segment = hand\n",
    "\n",
    "                # Draw contours around hand segment\n",
    "                cv2.drawContours(frame_copy, [hand_segment + (ROI_right, ROI_top)], -1, (255, 0, 0),1)\n",
    "\n",
    "                cv2.putText(frame_copy, str(num_frames)+\"For \" + str(element), (70, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "                # Also display the thresholded image\n",
    "                cv2.imshow(\"Thresholded Hand Image\", thresholded)\n",
    "\n",
    "        else: \n",
    "\n",
    "            # Segmenting the hand region...\n",
    "            hand = segmentingHand(gray_frame)\n",
    "\n",
    "            # Checking if we are able to detect the hand...\n",
    "            if hand is not None:\n",
    "\n",
    "                # unpack the thresholded img and the max_contour...\n",
    "                thresholded, hand_segment = hand\n",
    "\n",
    "                # Drawing contours around hand segment\n",
    "                cv2.drawContours(frame_copy, [hand_segment + (ROI_right, ROI_top)], -1, (255, 0, 0),1)\n",
    "\n",
    "                cv2.putText(frame_copy, str(num_frames), (70, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "                #cv2.putText(frame_copy, str(num_frames)+\"For\" + str(element), (70, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "                cv2.putText(frame_copy, str(num_imgs_taken) + 'images' +\"For\" + str(element), (200, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "                # Displaying the thresholded image\n",
    "                cv2.imshow(\"Thresholded Hand Image\", thresholded)\n",
    "                if num_imgs_taken <= 300:\n",
    "                    #cv2.imwrite(r\"D:\\\\gesture\\\\train\\\\\"+str(element)+\"\\\\\" + str(num_imgs_taken+300) + '.jpg', thresholded)\n",
    "                    #cv2.imwrite(r\"D:\\\\gesture\\\\x\"+\"\\\\\" + str(num_imgs_taken) + '.jpg', thresholded):\n",
    "                    if(num_imgs_taken<200):\n",
    "                        if cv2.imwrite(train_path + \"\\\\\" + str(num_imgs_taken) + '.jpg', thresholded):\n",
    "                            print('success')\n",
    "                    else:\n",
    "                        if cv2.imwrite(test_path + \"\\\\\" + str(num_imgs_taken) + '.jpg', thresholded):\n",
    "                            print('success')\n",
    "                else:\n",
    "                    break\n",
    "                num_imgs_taken +=1\n",
    "            else:\n",
    "                cv2.putText(frame_copy, 'No hand detected...', (200, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "        # Drawing ROI on frame copy\n",
    "        cv2.rectangle(frame_copy, (ROI_left, ROI_top), (ROI_right, ROI_bottom), (255,128,0), 3)\n",
    "\n",
    "        \n",
    "        # increment the number of frames for tracking\n",
    "        num_frames += 1\n",
    "\n",
    "        # Display the frame with segmented hand\n",
    "        cv2.imshow(\"Sign Detection\", frame_copy)\n",
    "\n",
    "        # Closing windows with Esc key...(any other key with ord can be used too.)\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "    # Releasing camera & destroying all the windows...\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cam.release()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5891f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "\n",
    "        # filpping the frame to prevent inverted image of captured frame...\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    frame_copy = frame.copy()\n",
    "\n",
    "    roi = frame[ROI_top:ROI_bottom, ROI_right:ROI_left]\n",
    "\n",
    "    gray_frame = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "#     gray_frame = cv2.GaussianBlur(gray_frame, (9, 9), 0)\n",
    "    edges=cv2.Canny(gray_frame,150,200)\n",
    "    cv2.imshow('grayframe',gray_frame)\n",
    "    cv2.imshow('edges',edges)\n",
    "    contours, hierarchy = cv2.findContours(edges, \n",
    "    cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    cv2.imshow('Canny Edges After Contouring', edges)\n",
    "    cv2.drawContours(edges, contours, -1, (255, 255, 255),)\n",
    "    cv2.imshow('after contours',edges)\n",
    "    k=cv2.waitKey(1) & 0xFF\n",
    "    if k==27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cam.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e73dda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "\n",
    "        # filpping the frame to prevent inverted image of captured frame...\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    frame_copy = frame.copy()\n",
    "\n",
    "    roi = frame[ROI_top:ROI_bottom, ROI_right:ROI_left]\n",
    "\n",
    "    gray_frame = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (9, 9), 0)\n",
    "    th3 = cv2.adaptiveThreshold(gray_frame,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv2.THRESH_BINARY,11,2)\n",
    "    contours, hierarchy = cv2.findContours(th3, \n",
    "        cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    cv2.imshow('guassian threshold',th3)\n",
    "    cv2.drawContours(th3, contours, -1, (0, 0, 0),2)\n",
    "    cv2.imshow('after drawing contours',th3)\n",
    "    k=cv2.waitKey(1) & 0xFF\n",
    "    if k==27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cam.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c30d5a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-kh7iq4w7\\opencv\\modules\\photo\\src\\denoising.cpp:178: error: (-5:Bad argument) Type of input image should be CV_8UC3 or CV_8UC4! in function 'cv::fastNlMeansDenoisingColored'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-b7ec80d2e646>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mth3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madaptiveThreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray_frame\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mADAPTIVE_THRESH_GAUSSIAN_C\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_BINARY_INV\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mth3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_BINARY_INV\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_OTSU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mdenoised_image\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfastNlMeansDenoisingColored\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     contours, hierarchy = cv2.findContours(th3, \n\u001b[0;32m     18\u001b[0m         cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-kh7iq4w7\\opencv\\modules\\photo\\src\\denoising.cpp:178: error: (-5:Bad argument) Type of input image should be CV_8UC3 or CV_8UC4! in function 'cv::fastNlMeansDenoisingColored'\n"
     ]
    }
   ],
   "source": [
    "cam=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "\n",
    "        # filpping the frame to prevent inverted image of captured frame...\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    frame_copy = frame.copy()\n",
    "\n",
    "    roi = frame[ROI_top:ROI_bottom, ROI_right:ROI_left]\n",
    "\n",
    "    gray_frame = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (5, 5), 2)\n",
    "    th3 = cv2.adaptiveThreshold(gray_frame,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,11,2)\n",
    "    ret, test_image = cv2.threshold(th3, 70, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    denoised_image= cv2.fastNlMeansDenoisingColored(test_image,None,10,7,21)\n",
    "    contours, hierarchy = cv2.findContours(th3, \n",
    "        cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    cv2.imshow('guassian+otsu threshold',test_image)\n",
    "    cv2.drawContours(test_image, contours, -1, (0, 0, 0),2)\n",
    "    cv2.imshow('after drawing contours',test_image)\n",
    "    denoised_image= cv2.fastNlMeansDenoisingColored(test_image,None,10,7,21)\n",
    "    cv2.imshow('denoised image',denoised_image)\n",
    "    k=cv2.waitKey(1) & 0xFF\n",
    "    if k==27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cam.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
