{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35d7a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten \n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "# import PIL\n",
    "# import PIL.Image\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "warnings.simplefilter(action='ignore',category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f63f7e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Major Project\\Data\\train E:\\Major Project\\Data\\test\n"
     ]
    }
   ],
   "source": [
    "path=os.getcwd()\n",
    "train_path=os.path.join(path,os.path.join('Data','train'))\n",
    "test_path=os.path.join(path,os.path.join('Data','test'))\n",
    "print(train_path,test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08f2577c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'E:\\\\Major Project\\\\Data\\\\train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-28d35ba288b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessing_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m26\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[0;32m    940\u001b[0m             \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m     \"\"\"\n\u001b[1;32m--> 942\u001b[1;33m     return DirectoryIterator(\n\u001b[0m\u001b[0;32m    943\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dtype'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m     super(DirectoryIterator, self).__init__(\n\u001b[0m\u001b[0;32m    381\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_data_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'E:\\\\Major Project\\\\Data\\\\train'"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_path, target_size=(64,64), class_mode='categorical', batch_size=(26*200),shuffle=True)\n",
    "images,labels=next(train_batches)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4c69c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e7ea189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(30,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db081824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotImages(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48bfaf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 0 0 0 0 1 0 "
     ]
    }
   ],
   "source": [
    "for i in labels:\n",
    "    print(np.argmax(i),end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e7ab7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model=Sequential()\n",
    "nn_model.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=(64,64,3)))\n",
    "nn_model.add(MaxPool2D(pool_size=(2,2),strides=2))\n",
    "nn_model.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu',padding='same'))\n",
    "nn_model.add(MaxPool2D(pool_size=(2,2),strides=2))\n",
    "nn_model.add(Conv2D(filters=128,kernel_size=(3,3),activation='relu',padding='valid'))\n",
    "nn_model.add(MaxPool2D(pool_size=(2,2),strides=2))\n",
    "\n",
    "nn_model.add(Flatten())\n",
    "\n",
    "nn_model.add(Dense(64,activation='relu'))\n",
    "nn_model.add(Dense(128,activation='relu'))\n",
    "nn_model.add(Dropout(0.2))\n",
    "nn_model.add(Dense(128,activation='relu'))\n",
    "nn_model.add(Dropout(0.2))\n",
    "nn_model.add(Dense(2,activation=\"softmax\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f0d5d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 31, 31, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 13, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                294976    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 413,314\n",
      "Trainable params: 413,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82223e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn_model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0001)\n",
    "# early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0005)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78b2abc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.9170 - accuracy: 0.7692\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 3.2970 - accuracy: 0.5385\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1.3210 - accuracy: 0.7308\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.2077 - accuracy: 0.9615\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0334 - accuracy: 1.0000\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.3914 - accuracy: 0.8846\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.1950 - accuracy: 0.9615\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0905 - accuracy: 0.9615\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0270 - accuracy: 1.0000\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0276 - accuracy: 1.0000\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n"
     ]
    }
   ],
   "source": [
    "histroy1= nn_model.fit(images,labels,epochs=10,callbacks=[reduce_lr,early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1908f9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.9169942140579224,\n",
       "  3.296950340270996,\n",
       "  1.3210114240646362,\n",
       "  0.2077057659626007,\n",
       "  0.03342778980731964,\n",
       "  0.39135777950286865,\n",
       "  0.19495922327041626,\n",
       "  0.09048417955636978,\n",
       "  0.02703755907714367,\n",
       "  0.027591388672590256],\n",
       " 'accuracy': [0.7692307829856873,\n",
       "  0.5384615659713745,\n",
       "  0.7307692170143127,\n",
       "  0.9615384340286255,\n",
       "  1.0,\n",
       "  0.8846153616905212,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  1.0,\n",
       "  1.0],\n",
       " 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histroy1.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d79e926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions\n",
      "0 0 1 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 0 0 0 0 1 0 actual values\n",
      "0 0 1 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 0 0 0 0 1 0 "
     ]
    }
   ],
   "source": [
    "predictions=nn_model.predict(images)\n",
    "print('predictions')\n",
    "for i in predictions:\n",
    "    print(np.argmax(i),end=\" \")\n",
    "print('actual values')\n",
    "for i in labels:\n",
    "    print(np.argmax(i),end=\" \")\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
